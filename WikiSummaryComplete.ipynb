{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ob6Jc07nKjZ"
   },
   "source": [
    "##<font color=\"#fd79a8\">Extraction-Based Summarizer <br><font color=\"#48dbfb\">Scraped Wikipedia articles using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L80gVJiZ1fvJ",
    "outputId": "fe6b8c43-429b-4e2d-b959-fb66fd82a4dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mirfarhanali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import sys\n",
    "import csv \n",
    "\n",
    "#persian cuisine\n",
    "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Iranian_cuisine')\n",
    "article = scraped_data.read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "i_4EmP8l1tLi"
   },
   "outputs": [],
   "source": [
    "# Removing Square Brackets and Extra Spaces\n",
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "#any whitespace character \\s+\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u-AKwDkc15h6"
   },
   "outputs": [],
   "source": [
    "# Removing special characters and digits\n",
    "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "#any whitespace character \\s+\n",
    "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3dlAgyRvLa4"
   },
   "source": [
    "##<font color=\"#fd79a8\">Convert paragraphs to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q1BxJpQx15ss"
   },
   "outputs": [],
   "source": [
    "sentence_list = nltk.sent_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGWRc5NY2g8J",
    "outputId": "3e34129f-9cec-4590-a49d-829e9c061984"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mirfarhanali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZ-LlCwBwE7J"
   },
   "source": [
    "###<font color=\"#fd79a8\"> Loop to calculate the word frequencies. <br>Tokenize the sentences<br>if word is not a stopword and is in the word list, the count is added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fA4mWOgK2X6Y"
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in nltk.word_tokenize(formatted_article_text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4v06sl2xA_v"
   },
   "source": [
    "###<font color=\"#48dbfb\"> Keys() method<br>The keys() method returns a view object. The view object contains the keys of the dictionary, as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u70SSN1cxO2i",
    "outputId": "1c296a10-9c8c-4763-b48c-ffde6c69feb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['brand', 'series', 'price'])\n"
     ]
    }
   ],
   "source": [
    "shoe = {\n",
    "  \"brand\": \"Nike\",\n",
    "  \"series\": \"Air Max\",\n",
    "  \"price\": 100\n",
    "}\n",
    "\n",
    "var = shoe.keys()\n",
    "\n",
    "print(var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOPnTZ9ixUvl"
   },
   "source": [
    "###<font color=\"#48dbfb\">When an item is added in the dictionary, the view object also gets updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5rYePFbxSd0",
    "outputId": "f423287a-334c-4269-defe-c72a46bccf95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['brand', 'series', 'price', 'color'])\n"
     ]
    }
   ],
   "source": [
    "shoe[\"color\"] = \"red\"\n",
    "\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzSatUTS8WK7"
   },
   "source": [
    "###<font color=\"#48dbfb\">Find weighted frequency of occurence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D34gqm-42lBq"
   },
   "outputs": [],
   "source": [
    "maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw5PmlZHycfs",
    "outputId": "e18f329d-c43e-4c0b-fed2-6cf8a270421c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Nike', 'Air Max', 100])\n"
     ]
    }
   ],
   "source": [
    "shoe = {\n",
    "  \"brand\": \"Nike\",\n",
    "  \"series\": \"Air Max\",\n",
    "  \"price\": 100\n",
    "}\n",
    "\n",
    "var = shoe.values()\n",
    "\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2LMj2pa8L0k"
   },
   "source": [
    "###<font color=\"#48dbfb\">Replace words with weighted frequency in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fNUVxbcD2lOD"
   },
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0mMnhCX8lLJ"
   },
   "source": [
    "####<font color=\"#fd79a8\">Heap queue <br>heap queue algorithm, also known as the priority queue algorithm<br>It makes it possible to view the data (words/scores) -  our heap, as a regular Python list<br><font color=\"#0abde3\">heapq.nlargest(n, iterable, key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "ThhA39562rxN",
    "outputId": "eb3486cf-b191-4763-9cbe-e54d65fcef21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Typical Iranian cuisine includes a wide variety of dishes, including several forms of kebab, stew, soup, and pilaf dishes, as well as various salads, desserts, pastries, and drinks. Apart from dishes of rice with kebab or stew, there are various rice-based Iranian dishes cooked in the traditional methods of polow and dami. It is followed by six chapters on the preparation of various dishes: four on rice dishes, one on qalya, and one on ƒÅsh. Baluchi cuisine also includes several date-based dishes, as well as various types of bread. Unripe grapes are also used whole in some dishes such as khoresh e qure (lamb stew with sour grapes). Rose water, a flavored water made by steeping rose petals in water, is also a traditional and common ingredient in many Iranian dishes. Main dishes are concentrated in the middle, surrounded by smaller dishes containing appetizers, condiments, and side dishes, all of which are nearest to the diners. It is mainly used within soup and stew dishes, but also to simmer a type of squash dolma. Bastani e zaferani, Persian for \"saffron ice cream\", is a traditional Iranian ice cream which is also commonly referred to as \"the traditional ice cream\". A polow dish includes rice stuffed with cuts of vegetables, fruits, and beans, usually accompanied by either chicken or red meat.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "summary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "summary = ' '.join(summary_sentences)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WikiSummaryComplete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
